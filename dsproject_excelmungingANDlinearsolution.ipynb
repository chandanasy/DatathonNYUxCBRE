{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "drive_dir1 = '/content/drive/MyDrive/datathon2024/Atlanta_supply_dat_UC_buildings.csv'\n",
        "drive_dir2 = '/content/drive/MyDrive/datathon2024/More_Atlanta_Supply.csv'\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Read the CSV file into a DataFrame, then merge along rows\n",
        "df1 = pd.read_csv(drive_dir1)\n",
        "df2 = pd.read_csv(drive_dir2)\n",
        "\n",
        "df = pd.concat([df1, df2], ignore_index=True, sort=False)\n",
        "df=df.dropna(subset=['Size_sf', 'YearQuarterGroundBroken'])\n",
        "\n",
        "# Define a function to calculate TimeCompleted based on Size_sf\n",
        "def calculate_time_completed(row):\n",
        "    if row['Size_sf'] < 99999:\n",
        "        quarters_to_add = 2\n",
        "    elif 100000 < row['Size_sf'] < 299999:\n",
        "        quarters_to_add = 3\n",
        "    elif 300000 < row['Size_sf'] < 599999:\n",
        "        quarters_to_add = 4\n",
        "    elif 600000 < row['Size_sf'] < 999999:\n",
        "        quarters_to_add = 5\n",
        "    else:\n",
        "        quarters_to_add = 6\n",
        "\n",
        "    year, quarter = divmod(row['YearQuarterGroundBroken'], 1)\n",
        "    quarter += quarters_to_add\n",
        "    year += math.floor(quarter / 4)\n",
        "    quarter %= 4\n",
        "    if quarter == 0:\n",
        "        quarter = 4\n",
        "    return year + quarter  # Format as year.quarter\n",
        "# Apply the function to create the TimeCompleted column\n",
        "df['completions_sf'] = df.apply(calculate_time_completed, axis=1)\n",
        "\n",
        "\n",
        "def fin_in_four(row):\n",
        "\n",
        "    if row['Size_sf'] < 99999:\n",
        "        quarters_to_add = 2\n",
        "    elif 100000 < row['Size_sf'] < 299999:\n",
        "        quarters_to_add = 3\n",
        "    elif 300000 < row['Size_sf'] < 599999:\n",
        "        quarters_to_add = 4\n",
        "    elif 600000 < row['Size_sf'] < 999999:\n",
        "        quarters_to_add = 5\n",
        "    else:\n",
        "        quarters_to_add = 6\n",
        "\n",
        "    if quarters_to_add <= 5:\n",
        "        fin_in_four_quarters = True\n",
        "    else:\n",
        "        fin_in_four_quarters = False\n",
        "    return fin_in_four_quarters\n",
        "df['fin_in_four_quarters'] = df.apply(fin_in_four, axis=1)\n",
        "# Print the updated DataFrame\n",
        "print(df[['completions_sf', 'YearQuarterGroundBroken']], sum(df['fin_in_four_quarters']))\n",
        "#df.drop(['fin_in_four_quarters'], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3mFF0lMEEMv",
        "outputId": "4e3d7368-3b70-469c-d6fa-0edf89fbfa61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     completions_sf  YearQuarterGroundBroken\n",
            "0            2026.1                   2024.1\n",
            "1            2025.2                   2023.2\n",
            "2            2026.3                   2023.3\n",
            "3            2026.4                   2023.4\n",
            "4            2026.2                   2023.2\n",
            "..              ...                      ...\n",
            "672          2026.1                   2023.1\n",
            "673          2026.1                   2024.1\n",
            "674          2026.2                   2023.2\n",
            "675          2024.4                   2022.4\n",
            "676          2027.1                   2024.1\n",
            "\n",
            "[676 rows x 2 columns] 638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dir = '/content/drive/MyDrive/datathon2024/Atlanta_supply_dat_stock_data.csv'\n",
        "\n",
        "d_f = pd.read_csv(drive_dir)\n",
        "d_f['stock_SF'] = d_f['Stock_sf'] + d_f['Completions_sf']\n",
        "\n",
        "d_f['Stock_Under_Construction_sf'] = 0\n",
        "d_f['under_construction_as_a_percentage_of_Stock'] = 0\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(d_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iKDumv2KiLz",
        "outputId": "07bbeb8f-98e0-44e0-9ab2-25bdaaf2226f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   MarketCode MarketName  YearQuarter  Stock_sf  Completions_sf  \\\n",
            "0      ATLANT    Atlanta       2000.1    397465            4394   \n",
            "1      ATLANT    Atlanta       2000.2    401081            3616   \n",
            "2      ATLANT    Atlanta       2000.3    405850            4769   \n",
            "3      ATLANT    Atlanta       2000.4    412672            6822   \n",
            "4      ATLANT    Atlanta       2001.1    416867            4195   \n",
            "..        ...        ...          ...       ...             ...   \n",
            "91     ATLANT    Atlanta       2022.4    696700            9045   \n",
            "92     ATLANT    Atlanta       2023.1    703240            6540   \n",
            "93     ATLANT    Atlanta       2023.2    708037            4797   \n",
            "94     ATLANT    Atlanta       2023.3    717677            9640   \n",
            "95     ATLANT    Atlanta       2023.4    730346           12669   \n",
            "\n",
            "    Stock_Under_Construction_sf  under_construction_as_a_percentage_of_Stock  \\\n",
            "0                             0                                            0   \n",
            "1                             0                                            0   \n",
            "2                             0                                            0   \n",
            "3                             0                                            0   \n",
            "4                             0                                            0   \n",
            "..                          ...                                          ...   \n",
            "91                            0                                            0   \n",
            "92                            0                                            0   \n",
            "93                            0                                            0   \n",
            "94                            0                                            0   \n",
            "95                            0                                            0   \n",
            "\n",
            "    stock_SF  \n",
            "0     401859  \n",
            "1     404697  \n",
            "2     410619  \n",
            "3     419494  \n",
            "4     421062  \n",
            "..       ...  \n",
            "91    705745  \n",
            "92    709780  \n",
            "93    712834  \n",
            "94    727317  \n",
            "95    743015  \n",
            "\n",
            "[96 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming df is your DataFrame with columns including sq ft, stage completed, and output quarters\n",
        "# If df is not defined, load or create your DataFrame first\n",
        "\n",
        "image_paths = []\n",
        "image_labels = []\n",
        "for data_dir, label in zip(data_dirs, labels):\n",
        "    folder_path = os.path.join(drive_dir, data_dir)\n",
        "    images = os.listdir(folder_path)\n",
        "    for image in images:\n",
        "        image_paths.append(os.path.join(folder_path, image))\n",
        "        image_labels.append(label)\n",
        "        list = image.split(\"_\")\n",
        "        #print(list)\n",
        "        Latitude = []\n",
        "        Longitude = []\n",
        "\n",
        "        for i in list:\n",
        "        # Extract the numerical parts and convert them to float\n",
        "        latitude = float(list[1])\n",
        "        # Extract the numerical part of the entry in list[2] for longitude\n",
        "        longitude = float(list[2].split('.')[0] + '.' + list[2].split('.')[1])  # Assuming the numerical part is before the dot\n",
        "\n",
        "        # Append the numerical parts to the respective lists\n",
        "        Latitude.append(latitude)\n",
        "        Longitude.append(longitude)\n",
        "\n",
        "        for keys, values in df[\"Latitude\"].items():\n",
        "            if Latitude is in (df[\"Latitude\"].values) and Longitude is in (df[\"Longitude\"].values):\n",
        "                df['stage_completed'] = label\n",
        "\n",
        "print(Latitude, Longitude)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = df[['stock_SF', 'stage_completed']]\n",
        "y = df['QuartersTrackedInDatabase']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing steps for different types of features\n",
        "numeric_features = ['stock_SF']\n",
        "categorical_features = ['stage_completed']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline with preprocessing and linear regression model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "aeGi3LaJMnB5",
        "outputId": "a319720b-54ac-4e9c-da70-57393306edd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33.9960678] [-83.9604705]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nX = df[['stock_SF', 'stage_completed']]  \\ny = df['QuartersTrackedInDatabase']  \\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Define preprocessing steps for different types of features\\nnumeric_features = ['stock_SF']\\ncategorical_features = ['stage_completed']\\n\\nnumeric_transformer = Pipeline(steps=[\\n    ('scaler', StandardScaler())\\n])\\n\\ncategorical_transformer = Pipeline(steps=[\\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\\n])\\n\\npreprocessor = ColumnTransformer(\\n    transformers=[\\n        ('num', numeric_transformer, numeric_features),\\n        ('cat', categorical_transformer, categorical_features)\\n    ])\\n\\n# Create a pipeline with preprocessing and linear regression model\\nmodel = Pipeline(steps=[\\n    ('preprocessor', preprocessor),\\n    ('regressor', LinearRegression())\\n])\\n\\n# Fit the model\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions\\ny_pred = model.predict(X_test)\\n\\n# Evaluate the model\\nmse = mean_squared_error(y_test, y_pred)\\nprint(f'Mean Squared Error: {mse}')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}