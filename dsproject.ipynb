{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT9IioIEQOle"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# Define functions for evaluation metrics and plotting\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training vs Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Set up your Google Drive directory and other configurations\n",
        "drive_dir = '/content/drive/MyDrive/datathon2024'\n",
        "data_dirs = ['underdeveloped_atl', 'ground_broken_atl', 'concrete_pad_atl', 'framing_up_atl', 'near_completion_atl']\n",
        "labels = ['underdeveloped_atl', 'ground_broken_atl', 'concrete_pad_atl', 'framing_up_atl', 'near_completion_atl']\n",
        "batch_size = 32\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Load and preprocess images function\n",
        "def load_and_preprocess_image(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_image(image, channels=3)\n",
        "    image.set_shape([None, None, 3])  # Set explicit shape before resizing\n",
        "    image = tf.image.resize(image, [input_shape[0], input_shape[1]])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Load data and split into train, validation, and test sets\n",
        "image_paths = []\n",
        "image_labels = []\n",
        "for data_dir, label in zip(data_dirs, labels):\n",
        "    folder_path = os.path.join(drive_dir, data_dir)\n",
        "    images = os.listdir(folder_path)\n",
        "    for image in images:\n",
        "        image_paths.append(os.path.join(folder_path, image))\n",
        "        image_labels.append(label)\n",
        "\n",
        "# Encode string labels to integer labels\n",
        "label_encoder = LabelEncoder()\n",
        "image_labels_encoded = label_encoder.fit_transform(image_labels)\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, image_labels_encoded, test_size=0.2, random_state=42)\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    train_paths, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "def create_dataset(paths, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    dataset = dataset.map(load_and_preprocess_image)\n",
        "    dataset = dataset.shuffle(len(paths)).batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = create_dataset(train_paths, train_labels)\n",
        "val_dataset = create_dataset(val_paths, val_labels)\n",
        "test_dataset = create_dataset(test_paths, test_labels)\n",
        "\n",
        "# Define and compile the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(labels), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath='best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "]\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset, callbacks=callbacks)\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(history)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f'Test accuracy: {test_accuracy}')\n",
        "\n",
        "# Load the best model from ModelCheckpoint\n",
        "best_model = tf.keras.models.load_model('best_model.h5')\n",
        "\n"
      ]
    }
  ]
}